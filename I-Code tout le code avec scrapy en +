import requests
import time
from pymongo import MongoClient
import matplotlib.pyplot as plt
import seaborn as sns
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import numpy as np
import os
from dotenv import load_dotenv

# === CONFIGURATION ===
GNEWS_API_KEY = "e275d891ea6264bcdc91bfd73567c65b"
GNEWS_API_URL = "https://gnews.io/api/v4/search"

NEWSAPI_KEY = "4aa659261bd2443997ffc38ef5c851fd"
NEWSAPI_URL = "https://newsapi.org/v2/everything"

USE_CUSTOM_MODEL = False

# === MONGO ===
client = MongoClient("mongodb://localhost:27017/")
db = client["world_mood"]
collection = db["articles"]

# === ANALYSE DES √âMOTIONS ===
model_name = "j-hartmann/emotion-english-distilroberta-base"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)
labels = ['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']

# === R√âCUP√âRATION ARTICLES ===
def get_articles_newsapi(query="politique", language="fr", page_size=5):
    params = {
        "q": query,
        "language": language,
        "pageSize": page_size,
        "apiKey": NEWSAPI_KEY
    }
    response = requests.get(NEWSAPI_URL, params=params)
    if response.status_code != 200:
        print("‚ùå NewsAPI:", response.json())
        return []

    return [
        {
            "title": a["title"],
            "author": a.get("author", "Inconnu"),
            "publication_date": a["publishedAt"],
            "content": a.get("content", ""),
            "url": a["url"],
            "source": a["source"]["name"],
            "tags": query,
            "lang": language
        }
        for a in response.json().get("articles", [])
    ]

def get_articles_gnews(query="politique", lang="fr", max_articles=10, delay=5):
    articles = []
    while len(articles) < max_articles:
        params = {
            "q": query,
            "lang": lang,
            "max": max_articles,
            "token": GNEWS_API_KEY
        }
        response = requests.get(GNEWS_API_URL, params=params)
        if response.status_code != 200:
            print("‚ùå GNews:", response.json())
            break

        new_articles = [
            {
                "title": a["title"],
                "author": a.get("source", {}).get("name", "Inconnu"),
                "publication_date": a["publishedAt"],
                "content": a.get("content", ""),
                "url": a["url"],
                "source": a.get("source", {}).get("name", "Inconnu"),
                "tags": query,
                "lang": lang
            }
            for a in response.json().get("articles", [])
        ]
        articles.extend(new_articles)

        if len(articles) < max_articles:
            time.sleep(delay)

    return articles[:max_articles]

def get_articles_scrapy(max_articles=10):
    # Impl√©mentation simul√©e, √† remplacer avec Scrapy r√©el
    return []

def fetch_articles(method="gnews", query="politique", lang="fr", max_articles=10):
    if method == "newsapi":
        return get_articles_newsapi(query=query, language=lang, page_size=max_articles)
    elif method == "gnews":
        return get_articles_gnews(query=query, lang=lang, max_articles=max_articles)
    elif method == "scrapy":
        return get_articles_scrapy(max_articles=max_articles)
    else:
        print("‚ùå M√©thode de collecte inconnue :", method)
        return []

# === STOCKAGE ===
def save_articles_to_mongo(articles):
    for article in articles:
        if not collection.find_one({"url": article["url"]}):
            collection.insert_one(article)

# === √âTIQUETAGE DES √âMOTIONS ===
def annotate_articles_with_emotions():
    for article in collection.find({"emotion": {"$exists": False}}):
        content = article.get("content") or article.get("title")
        inputs = tokenizer(content, return_tensors="pt", truncation=True)
        with torch.no_grad():
            logits = model(**inputs).logits
        scores = torch.nn.functional.softmax(logits, dim=1)[0]
        emotion = labels[scores.argmax().item()]
        collection.update_one({"_id": article["_id"]}, {"$set": {"emotion": emotion}})

# === VISUALISATION ===
def plot_emotions():
    data = list(collection.find({"emotion": {"$exists": True}}))
    if not data:
        print("Aucune donn√©e annot√©e.")
        return

    df = {}
    for d in data:
        lang = d.get("lang", "und")
        emo = d["emotion"]
        df[(lang, emo)] = df.get((lang, emo), 0) + 1

    import pandas as pd
    df = pd.DataFrame([{"lang": k[0], "emotion": k[1], "count": v} for k, v in df.items()])
    plt.figure(figsize=(10, 6))
    sns.barplot(data=df, x="emotion", y="count", hue="lang")
    plt.title("Distribution des √©motions par langue")
    plt.tight_layout()
    plt.show()

# === EX√âCUTION PRINCIPALE ===
if __name__ == "__main__":
    method = "gnews"  # "newsapi", "gnews", ou "scrapy"
    topics = ["politique", "√©cologie", "technologie"]
    langs = ["fr", "en"]

    for topic in topics:
        for lang in langs:
            print(f"\nüåç Collecte '{topic}' en {lang} via {method}")
            articles = fetch_articles(method=method, query=topic, lang=lang, max_articles=10)
            save_articles_to_mongo(articles)

    annotate_articles_with_emotions()
    plot_emotions()


